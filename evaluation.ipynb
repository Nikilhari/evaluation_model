{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from functools import lru_cache\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load the set of stopwords and define negation words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "negation_words = {\"not\", \"n't\", \"no\", \"never\"}\n",
    "\n",
    "# Load the SBERT model (fine-tuned on engineering texts if available)\n",
    "model = SentenceTransformer('allenai/scibert_scivocab_uncased')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower().translate(str.maketrans('', '', string.punctuation))\n",
    "    words = text.split()\n",
    "    processed_words = []\n",
    "    original_words = []\n",
    "    negate = False\n",
    "\n",
    "    for word in words:\n",
    "        if word in stop_words and word not in negation_words:\n",
    "            continue\n",
    "        if word in negation_words:\n",
    "            negate = True\n",
    "            original_words.append(word)\n",
    "            continue\n",
    "        if negate:\n",
    "            processed_words.append(\"NOT_\" + word)\n",
    "            negate = False\n",
    "        else:\n",
    "            processed_words.append(word)\n",
    "        original_words.append(word)\n",
    "\n",
    "    return processed_words, original_words\n",
    "\n",
    "def check_negation(original_words):\n",
    "    return any(word in negation_words for word in original_words)\n",
    "\n",
    "def remove_redundant_words(words):\n",
    "    return list(dict.fromkeys(words))\n",
    "\n",
    "def remove_question_keywords(answer_words, question_words):\n",
    "    return [word for word in answer_words if word not in question_words]\n",
    "\n",
    "def compute_word_frequency_vector(words, unique_words):\n",
    "    word_freq = Counter(words)\n",
    "    vector = [word_freq[word] for word in unique_words]\n",
    "    return vector\n",
    "\n",
    "def classify_question(question):\n",
    "    explanation_keywords = {\"explain\", \"describe\", \"why\", \"how\"}\n",
    "    if any(keyword in question.lower() for keyword in explanation_keywords):\n",
    "        return \"explanation\"\n",
    "    return \"fact\"\n",
    "\n",
    "@lru_cache(maxsize=10000)\n",
    "def get_embedding(text):\n",
    "    return model.encode(text)\n",
    "\n",
    "def evaluate_with_keywords(reference_answer, candidate_answer, question):\n",
    "    question_processed, question_original = preprocess_text(question)\n",
    "    ref_processed, ref_original = preprocess_text(reference_answer)\n",
    "    cand_processed, cand_original = preprocess_text(candidate_answer)\n",
    "\n",
    "    ref_filtered = remove_question_keywords(ref_processed, question_processed)\n",
    "    cand_filtered = remove_question_keywords(cand_processed, question_processed)\n",
    "\n",
    "    ref_filtered = remove_redundant_words(ref_filtered)\n",
    "    cand_filtered = remove_redundant_words(cand_filtered)\n",
    "\n",
    "    unique_words = list(set(ref_filtered + cand_filtered))\n",
    "\n",
    "    ref_vector = compute_word_frequency_vector(ref_filtered, unique_words)\n",
    "    cand_vector = compute_word_frequency_vector(cand_filtered, unique_words)\n",
    "\n",
    "    ref_vector = np.array(ref_vector).reshape(1, -1)\n",
    "    cand_vector = np.array(cand_vector).reshape(1, -1)\n",
    "\n",
    "    cosine_sim = cosine_similarity(ref_vector, cand_vector)[0][0]\n",
    "    match_percentage = cosine_sim * 100\n",
    "\n",
    "    return match_percentage, ref_filtered, cand_filtered, question_processed, ref_original, cand_original, question_original\n",
    "\n",
    "def evaluate_with_sbert(reference_answer, candidate_answer, question):\n",
    "    ref_processed, ref_original = preprocess_text(reference_answer)\n",
    "    cand_processed, cand_original = preprocess_text(candidate_answer)\n",
    "\n",
    "    ref_embedding = get_embedding(\" \".join(ref_processed))\n",
    "    cand_embedding = get_embedding(\" \".join(cand_processed))\n",
    "\n",
    "    cosine_sim = cosine_similarity([ref_embedding], [cand_embedding])[0][0]\n",
    "    match_percentage = cosine_sim * 100\n",
    "\n",
    "    return match_percentage, ref_processed, cand_processed, preprocess_text(question)[0], ref_original, cand_original, preprocess_text(question)[1]\n",
    "\n",
    "def adjust_for_negation(match_percentage, question_original, ref_original, cand_original):\n",
    "    question_has_negation = check_negation(question_original)\n",
    "    ref_has_negation = check_negation(ref_original)\n",
    "    cand_has_negation = check_negation(cand_original)\n",
    "\n",
    "    if question_has_negation and ref_has_negation and cand_has_negation:\n",
    "        return match_percentage\n",
    "    elif cand_has_negation and not (question_has_negation or ref_has_negation):\n",
    "        match_percentage *= 0.3\n",
    "    elif (question_has_negation or ref_has_negation) and not cand_has_negation:\n",
    "        match_percentage *= 0.5\n",
    "\n",
    "    return match_percentage\n",
    "\n",
    "def generalize_score(sbert_score, keyword_score, question_original, ref_original, cand_original):\n",
    "    difference_threshold = 10.0\n",
    "\n",
    "    if abs(sbert_score - keyword_score) <= difference_threshold:\n",
    "        generalized_score = (sbert_score + keyword_score) / 2\n",
    "    else:\n",
    "        generalized_score = (sbert_score * 0.7) + (keyword_score * 0.3)\n",
    "\n",
    "    generalized_score = adjust_for_negation(generalized_score, question_original, ref_original, cand_original)\n",
    "\n",
    "    return generalized_score\n",
    "\n",
    "def evaluate_answer(reference_answer, candidate_answer, question):\n",
    "    question_type = classify_question(question)\n",
    "\n",
    "    if question_type == \"explanation\":\n",
    "        match_percentage, ref_keywords, cand_keywords, question_keywords, ref_original, cand_original, question_original = evaluate_with_sbert(reference_answer, candidate_answer, question)\n",
    "    else:\n",
    "        keyword_match_percentage, ref_keywords, cand_keywords, question_keywords, ref_original, cand_original, question_original = evaluate_with_keywords(reference_answer, candidate_answer, question)\n",
    "        sbert_match_percentage, _, _, _, _, _, _ = evaluate_with_sbert(reference_answer, candidate_answer, question)\n",
    "        match_percentage = generalize_score(sbert_match_percentage, keyword_match_percentage, question_original, ref_original, cand_original)\n",
    "\n",
    "    return match_percentage, ref_keywords, cand_keywords, question_keywords\n",
    "\n",
    "# Function to evaluate a specific input\n",
    "def evaluate_specific_input(reference_answer, candidate_answer, question):\n",
    "    match_percentage, ref_keywords, cand_keywords, question_keywords = evaluate_answer(reference_answer, candidate_answer, question)\n",
    "\n",
    "    print(f\"Generalized Match Percentage: {match_percentage:.2f}%\")\n",
    "    print(f\"Reference Keywords: {ref_keywords}\")\n",
    "    print(f\"Candidate Keywords: {cand_keywords}\")\n",
    "    print(f\"Question Keywords: {question_keywords}\")\n",
    "\n",
    "# Call the function with the given input\n",
    "evaluate_specific_input(reference_answer, candidate_answer, question)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
